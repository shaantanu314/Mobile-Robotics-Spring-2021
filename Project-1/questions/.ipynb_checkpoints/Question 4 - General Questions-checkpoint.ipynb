{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bones",
   "metadata": {},
   "source": [
    "Q1. In localization we are trying to find the location of the robot in the environment,i.e., the map that has been generated while in mapping we are trying to generate this map.\n",
    "\n",
    "In this project we are trying to find the location of the robot , thus it deals with Localization.\n",
    "The other part deals with mapping aspect of SLAM.\n",
    "\n",
    "\n",
    "Q2. If two nodes are in same part of the environment , then it is likely that they correspond to the same location (we can form a virtual edge between them). We use computer vision techiques for finding such correspondences ex : bag of visual words. We can also detect these based on the location of obstacles.\n",
    "\n",
    "\n",
    "Q3. We have already explained the structure of Jacobain in question 2 . The graph is not fully connected. It is difficult to form a pose-graph because we can form an edge between each and every node as we cant form loop closure constraint for each pair of nodes.\n",
    "\n",
    "\n",
    "Q4.In frontend, we construct a graph from the raw data. We do ICP in the frontend to find the transformation matrix. In the backend , we perform the optimization of the graph to minimize the residual error.\n",
    "Then the resulting node positions are sent again to the frontend where a new graph is generated from this data along with the previously optimized pose graph.\n",
    "\n",
    "<img src=\"../results/q4.jpeg\"/>\n",
    "\n",
    "Sources of noise:\n",
    "- error in LIDAR scan \n",
    "- drift due to friction from tyres\n",
    "- sensors are not perfect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
